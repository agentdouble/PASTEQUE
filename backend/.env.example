# Base configuration
ENV=development
API_PREFIX=/api
LOG_LEVEL=INFO
ALLOWED_ORIGINS=http://localhost:5173
BACKEND_DEV_URL=http://0.0.0.0:8000

# Data paths
DATA_ROOT=../data
VECTOR_STORE_PATH=../data/vector_store
DATA_TABLES_DIR=../data

# LLM configuration (local mode with vLLM)
# LLM_MODE=local
# VLLM_BASE_URL=http://127.0.0.1:8001/v1
# Z_LOCAL_MODEL=GLM-4.5-Air

# LLM configuration (API mode)
LLM_MODE=api
OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4
OPENAI_API_KEY=sk-your-key
LLM_MODEL=GLM-4.5-Air
OPENAI_TIMEOUT_S=90
LLM_MAX_TOKENS=1024

# MCP servers
# MCP_CONFIG_PATH=./config/mcp.yaml
# MCP_SERVERS_JSON=[{"name":"chart","url":"http://localhost:6001"}]

# Agent request caps (per-request). JSON mapping {agent: max}
# Available agent keys: router, chat, nl2sql, explorateur, analyste, redaction, axes, embedding, retrieval, mcp_chart, looper, tickets_chat
# Set 0 to disable an agent entirely for a request.
# Example: cap explorer to 2, analyst to 1, and disable MCP chart agent
# AGENT_MAX_REQUESTS={"explorateur":2, "analyste":1, "redaction":1, "mcp_chart":0}

# MindsDB
CONTAINER_RUNTIME=docker
MINDSDB_BASE_URL=http://127.0.0.1:47334/api
# Host-visible container settings (used by start.sh)
MINDSDB_CONTAINER_NAME=mindsdb_container
MINDSDB_HTTP_PORT=47334
MINDSDB_MYSQL_PORT=47335
# MINDSDB_TOKEN=
# MINDSDB_EMBEDDINGS_CONFIG_PATH=../data/mindsdb_embeddings.yaml
# MINDSDB_EMBEDDING_BATCH_SIZE=16
# MINDSDB_TIMEOUT_S=120
# RAG_TOP_N=3
# RAG_TABLE_ROW_CAP=500
# RAG_MAX_COLUMNS=6

# Embeddings (local sentence-transformers or API)
EMBEDDING_MODE=api
# EMBEDDING_MODEL=text-embedding-3-small          # API mode (OpenAI-compatible)
# EMBEDDING_LOCAL_MODEL=sentence-transformers/all-MiniLM-L6-v2  # Local mode (prioritaire sur default_model YAML)

# Retrieval agent (mise en avant) — tuning
# Optional model override; defaults to Z_LOCAL_MODEL / LLM_MODEL per mode
# RETRIEVAL_MODEL=
# Temperature and max tokens for the highlight synthesis
RETRIEVAL_TEMPERATURE=0.2
RETRIEVAL_MAX_TOKENS=220
# Inject analyst's textual answer into retrieval question (to guide investigation)
RETRIEVAL_INJECT_ANALYST=true

# Loop (résumés hebdo/mensuels)
LOOP_MAX_TICKETS=60
LOOP_TICKET_TEXT_MAX_CHARS=360
LOOP_MAX_DAYS=1
LOOP_MAX_WEEKS=1
LOOP_MAX_MONTHS=1
LOOP_TEMPERATURE=0.3
LOOP_MAX_TOKENS=800
LOOP_MAX_TICKETS_PER_CALL=400
LOOP_MAX_INPUT_CHARS=300000

# Database & auth
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/pasteque

# Router gate (appliqué à chaque message utilisateur)
# ROUTER_MODE can be: rule | local | api | false
#   - rule: deterministic, no LLM call
#   - local: uses VLLM_BASE_URL + (ROUTER_MODEL or Z_LOCAL_MODEL)
#   - api: uses OPENAI_BASE_URL + OPENAI_API_KEY + (ROUTER_MODEL or LLM_MODEL)
#   - false: disable router gate entirely
ROUTER_MODE=rule
# Optional model override for the router (defaults to Z_LOCAL_MODEL/LLM_MODEL)
# ROUTER_MODEL=
# UI animation level: sql | true | false
#   - sql   : keep existing SQL/plan streaming
#   - false : suppress plan/sql events (keep meta/evidence)
#   - true  : add lightweight 'anim' messages for human-friendly status
ANIMATION=sql
JWT_SECRET_KEY=change-me
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=240
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin

# NL→SQL helpers (always enabled, multi‑agent)
NL2SQL_DB_PREFIX=files
NL2SQL_SATISFACTION_MIN_ROWS=1
# Optional: data dictionary directory (YAML files per table)
DATA_DICTIONARY_DIR=../data/dictionary
DATA_DICTIONARY_MAX_CHARS=6000
EVIDENCE_LIMIT_DEFAULT=100
AGENT_OUTPUT_MAX_ROWS=200
AGENT_OUTPUT_MAX_COLUMNS=20
